{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import json\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from tflite_benchmark_executor import TfLiteBenchmarkExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "bench_executor = TfLiteBenchmarkExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing outputs\n",
      "Parsing inferences output\n",
      "Processing accuracy\n",
      "Parsing energy output\n",
      "Warning, time between clocks: 1012\n",
      "Warning, time between clocks: 1014\n",
      "Warning, time between clocks: 986\n",
      "Processing energy and power\n",
      "squeezenet/image0000_loop00.json\n"
     ]
    }
   ],
   "source": [
    "kernels = bench_executor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newKernels = []\n",
    "for kernel in kernels:\n",
    "    if(kernel[\"kernel\"] == \"CONV_2D\" or kernel[\"kernel\"] == \"MAX_POOL_2D\"):\n",
    "        newKernels.append(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kernels.json', 'w') as fp:\n",
    "    json.dump(newKernels, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('squezzenet_layers.txt') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    names = []\n",
    "    for layer in data:\n",
    "        names.append(layer)\n",
    "        \n",
    "    itens = []\n",
    "    for name in names:\n",
    "        itens.append(data[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36288\n"
     ]
    }
   ],
   "source": [
    "    conv_2d = [[],[],[],[],[],[],[],[],[],[],[]]\n",
    "    max_pol = [[],[],[],[],[],[],[],[],[],[],[]]\n",
    "    \n",
    "    conv_2d_time = [[],[],[],[],[],[],[],[],[],[],[]]\n",
    "    \n",
    "    for kernel,layer in zip(kernels,itens):\n",
    "        \n",
    "        if(kernel[\"kernel\"] == \"CONV_2D\"):\n",
    "        \n",
    "            conv_2d[0].extend(np.repeat(layer[\"output\"][0], len(kernel['energySpent'])))\n",
    "            conv_2d[1].extend(np.repeat(layer[\"output\"][1], len(kernel['energySpent'])))\n",
    "            conv_2d[2].extend(np.repeat(layer[\"output\"][2], len(kernel['energySpent'])))\n",
    "            conv_2d[3].extend(np.repeat(layer[\"filters\"][0], len(kernel['energySpent'])))\n",
    "            conv_2d[4].extend(np.repeat(layer[\"filters\"][1], len(kernel['energySpent'])))\n",
    "            conv_2d[5].extend(np.repeat(layer[\"filters\"][2], len(kernel['energySpent'])))\n",
    "            conv_2d[6].extend(np.repeat(layer[\"stride\"], len(kernel['energySpent'])))\n",
    "            conv_2d[7].extend(np.repeat(layer[\"input\"][0], len(kernel['energySpent'])))\n",
    "            conv_2d[8].extend(np.repeat(layer[\"input\"][1], len(kernel['energySpent'])))\n",
    "            conv_2d[9].extend(np.repeat(layer[\"input\"][2], len(kernel['energySpent'])))\n",
    "            conv_2d[10].extend(np.asarray(kernel['energySpent']))\n",
    "    \n",
    "            conv_2d_time[0].extend(np.repeat(layer[\"output\"][0], len(kernel['average_time_per_image'])))\n",
    "            conv_2d_time[1].extend(np.repeat(layer[\"output\"][1], len(kernel['average_time_per_image'])))\n",
    "            conv_2d_time[2].extend(np.repeat(layer[\"output\"][2], len(kernel['average_time_per_image'])))\n",
    "            conv_2d_time[3].extend(np.repeat(layer[\"filters\"][0], len(kernel['average_time_per_image'])))\n",
    "            conv_2d_time[4].extend(np.repeat(layer[\"filters\"][1], len(kernel['average_time_per_image'])))\n",
    "            conv_2d_time[5].extend(np.repeat(layer[\"filters\"][2], len(kernel['average_time_per_image'])))\n",
    "            conv_2d_time[6].extend(np.repeat(layer[\"stride\"], len(kernel['average_time_per_image'])))\n",
    "            conv_2d_time[7].extend(np.repeat(layer[\"input\"][0], len(kernel['average_time_per_image'])))\n",
    "            conv_2d_time[8].extend(np.repeat(layer[\"input\"][1], len(kernel['average_time_per_image'])))\n",
    "            conv_2d_time[9].extend(np.repeat(layer[\"input\"][2], len(kernel['average_time_per_image'])))\n",
    "            conv_2d_time[10].extend(np.asarray(kernel['average_time_per_image']))\n",
    "\n",
    "            continue\n",
    "        \n",
    "#         if(kernel[\"kernel\"] == \"MAX_POOL_2D\"):\n",
    "            \n",
    "#             max_pol[0].extend(np.repeat(layer[\"output\"][0], len(kernel[\"averagePower\"]))) \n",
    "#             max_pol[1].extend(np.repeat(layer[\"output\"][1], len(kernel[\"averagePower\"])))\n",
    "#             max_pol[2].extend(np.repeat(layer[\"output\"][2], len(kernel[\"averagePower\"])))\n",
    "#             max_pol[3].extend(np.repeat(layer[\"filters\"][0], len(kernel[\"averagePower\"])))\n",
    "#             max_pol[4].extend(np.repeat(layer[\"filters\"][1], len(kernel[\"averagePower\"])))\n",
    "#             max_pol[5].extend(np.repeat(layer[\"filters\"][2], len(kernel[\"averagePower\"])))\n",
    "#             max_pol[6].extend(np.repeat(layer[\"stride\"], len(kernel[\"averagePower\"])))\n",
    "#             max_pol[7].extend(np.repeat(layer[\"output\"][0], len(kernel[\"averagePower\"]))) \n",
    "#             max_pol[8].extend(np.repeat(layer[\"output\"][1], len(kernel[\"averagePower\"])))\n",
    "#             max_pol[9].extend(np.repeat(layer[\"output\"][2], len(kernel[\"averagePower\"])))\n",
    "# #             newData[name][\"executionTime\"] = np.asarray(kernel[\"executionTime\"])\n",
    "#             max_pol_y.extend(np.asarray(kernel[\"averagePower\"]))\n",
    "#             i = i + 1\n",
    "#             continue\n",
    "    training_conv = []\n",
    "    evaluating_conv = []\n",
    "    \n",
    "    conv_2d = np.transpose(conv_2d)\n",
    "    \n",
    "    np.random.shuffle(conv_2d)\n",
    "    \n",
    "    conv_2d = np.transpose(conv_2d)\n",
    "\n",
    "    percentage = 0.8\n",
    "    length = round(percentage * len(conv_2d[0]))\n",
    "    \n",
    "    for column in conv_2d:\n",
    "        training_conv.append(column[:length])\n",
    "        evaluating_conv.append(column[length:])\n",
    "\n",
    "    training_y = np.asarray(training_conv[10])\n",
    "    evaluating_y = np.asarray(evaluating_conv[10])\n",
    "    \n",
    "    training_conv = np.asarray(training_conv)\n",
    "    evaluating_conv = np.asarray(evaluating_conv)\n",
    "    \n",
    "    training_conv = training_conv[:-1]\n",
    "    evaluating_conv = evaluating_conv[:-1]\n",
    "    \n",
    "    print(len(training_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    training_conv_time = []\n",
    "    evaluating_conv_time = []\n",
    "    \n",
    "    conv_2d_time = np.transpose(conv_2d_time)\n",
    "    \n",
    "    np.random.shuffle(conv_2d_time)\n",
    "    \n",
    "    conv_2d_time = np.transpose(conv_2d_time)\n",
    "\n",
    "    percentage = 0.8\n",
    "    length = round(percentage * len(conv_2d_time[0]))\n",
    "    \n",
    "    for column in conv_2d:\n",
    "        training_conv_time.append(column[:length])\n",
    "        evaluating_conv_time.append(column[length:])\n",
    "        \n",
    "    training_y_time = np.asarray(training_conv_time[10])\n",
    "    evaluating_y_time = np.asarray(evaluating_conv_time[10])\n",
    "    \n",
    "    training_conv_time = np.asarray(training_conv_time)\n",
    "    evaluating_conv_time = np.asarray(evaluating_conv)\n",
    "    \n",
    "    training_conv_time = training_conv[:-1]\n",
    "    evaluating_conv_time = evaluating_conv[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    training_conv = np.transpose(training_conv)\n",
    "    evaluating_conv = np.transpose(evaluating_conv)\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(training_conv, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    training_conv_time = np.transpose(training_conv_time)\n",
    "    evaluating_conv_time = np.transpose(evaluating_conv_time)\n",
    "    \n",
    "    reg_time = LinearRegression()\n",
    "    reg_time.fit(training_conv_time, training_y_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_pred = reg.predict(evaluating_conv)\n",
    "    y_pred_time = reg_time.predict(evaluating_conv_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " 0.40539725720090614\n",
      "Coefficients: \n",
      " [-4.28364009e-03 -4.28364009e-03  3.44373651e-05 -2.37367223e-04\n",
      "  6.04266196e-03  6.04266196e-03 -3.61770053e-01  4.16338209e-03\n",
      "  4.16338209e-03  3.33249533e-04]\n",
      "Intercept: \n",
      " 0.67323525953932\n",
      "Coefficients: \n",
      " [-8.33784742e+07  8.33784742e+07  4.46647406e-04 -6.05188310e-04\n",
      " -1.93690280e+05  1.93690266e+05 -4.87942654e-01 -1.03892088e+07\n",
      "  1.03892088e+07]\n"
     ]
    }
   ],
   "source": [
    "    print('Intercept: \\n', reg.intercept_)\n",
    "    print('Coefficients: \\n', reg.coef_)\n",
    "    \n",
    "    print('Intercept: \\n', reg_time.intercept_)\n",
    "    print('Coefficients: \\n', reg_time.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521560300636334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    reg.score(evaluating_conv, evaluating_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7976683202049183"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    reg_time.score(evaluating_conv_time, evaluating_y_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.033494909277313835\n",
      "Mean Squared Error: 0.0030007180077792745\n",
      "Root Mean Squared Error: 0.054778809842668856\n"
     ]
    }
   ],
   "source": [
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(evaluating_y, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(evaluating_y, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(evaluating_y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0474922658665223\n",
      "Mean Squared Error: 0.004106628869386084\n",
      "Root Mean Squared Error: 0.06408298424220024\n"
     ]
    }
   ],
   "source": [
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(evaluating_y_time, y_pred_time))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(evaluating_y_time, y_pred_time))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(evaluating_y_time, y_pred_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
